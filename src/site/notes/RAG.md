---
{"dg-publish":true,"permalink":"/rag/"}
---



```ad-summary
title: RAG 是什麼？

**R**etrieval-**A**gumented **G**eneration

**RAG** 是一種調整推論(Inference)結果為目標的方法。
```

![RAG Process](https://miro.medium.com/v2/resize:fit:720/format:webp/1*33zN9mJugzjcSEcV-PAhig.gif)

使用者會藉由聊天機器人(Chatbot) 詢問問題，Chatbot 在讀取人類輸入的問題後，會**搜尋知識庫**中的文件內容，並**結合使用者輸入**來提供大語言模型 (LLM) 理解並 回傳給使用者做為使用者問題的回應。



### 搜尋知識庫 
RAG 過程中是 *如何搜尋知識庫的？* 我們可以從**如何建立知識庫**以及**如何搜尋到想要的文件**這兩個面向來探討。

- 如何建立知識庫？

知識庫建立主要是由**文字轉換為機器看得懂的語言**，方便日後機器的查詢與檢索。而機器看得懂得語言是一大串具備**高維度的向量**組成，如何將人類語言轉換為機器看得懂的語言，在機器學習領域的術語為 **Embedding**。

一般來說，轉換為機器語言的文件會將其放入資料庫中，以方便系統上快速查找。還記得先前提及機器看得懂的語言為**高維度向量**嗎？所以放高維度向量的資料庫則為**向量資料庫 (Vector Database)**。

- 如何搜尋到想要的文件？

搜尋文件的方式與關鍵字相同，是以輸入問句中有提及的文字進行查找。一般資料庫會使用**索引**的機制來使得資料庫中的資料能夠被快速搜尋，而在向量資料庫的索引也是相同可以藉由**關鍵字**來快速搜尋。而關鍵字可以使用其他的 Machine Learning 演算法來實作。



### 提示工程 
除了搜尋知識庫外，RAG 還有針對使用者的輸入先給予一個 **提示訊息 (Prompt)** 來提供情境上的限制。情境上的限制包含**不知道的情況回答不知道**，或是將**回答的內容限定為某個專業領域的專家**等。Prompt 主要是去調整 (Prompt Engineering) 大語言模型 (LLM) 的輸出。

> 等等，Prompt 最終也是要輸入大語言模型，所以理應來說也應該要使用 Embedding 轉換為機器看得懂的語言，不是嗎？**是，也不是。**

Prompt 的確會轉換為機器看得懂的語言，而是在輸入大語言模型的階段藉由 **Tokenizer** 轉換為向量，不是藉由 RAG 建立向量資料庫時使用的  Embedding 來轉換。



### 大語言模型
